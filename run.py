#!/usr/bin/env python

"""
Execute the voting schedule for today.

The schedule is stored in the `common.schedule_database_path` sqlite3 database,
which is generated by other scripts beforehand.

Executes the maximum 30 votes that haven't been done yet for each user,
and mark them as done in the schedule database.

This should be run at least once every day.

There is not problem if you run it more than once a day.

This can be run as a cron job. All output is logged to a file.

Consider using anacron for the job:
http://serverfault.com/questions/52335/job-scheduling-using-crontab-what-will-happen-when-computer-is-shutdown-during
which will work as soon as you turn on your computer.

You can interrupt this script with Ctrl + C
and restart it later on without problems.

Only answer uptvoting is currently supported.
"""

import csv
import datetime
import email.mime.text
import logging
import os.path
import random
import signal
import smtplib
import sqlite3
import subprocess
import sys
import threading
import time

import common
import email_credentials

# Don't do any operations to the Stack Overflow server.
# But do change local database. Used for testing.
dry_run_no_server = False

# Some exit statuses indicate that we should not send a notification email.
exit_status_success = 0
exit_status_404 = 65
exit_status_no_upvote_arrow = 66
# TODO deal with this case by emailing the admin to manually do the CAPTCHA.
exit_status_human_verification = 67
exit_status_cloudfare_attention_required = 68

max_failures_today = 30
first_tor_port = 9052

vote_not_done_query = 'WHERE vote_time IS NULL AND user_id = ? '

def send_email(subject, body=''):
    user = email_credentials.user
    recipient = email_credentials.recipient
    to = recipient if type(recipient) is list else [recipient]
    tos = ', '.join(to)
    server = smtplib.SMTP(email_credentials.server, 587)
    server.set_debuglevel(1)
    server.ehlo()
    server.starttls()
    server.login(user, email_credentials.password)
    msg = email.mime.text.MIMEText(body)
    msg['Subject'] = 'sofraud - ' + subject
    msg['From'] = user
    msg['To'] = tos
    message = msg.as_string()
    server.sendmail(user, to, message)
    server.quit()

class UserVotesThread(threading.Thread):
    def __init__(self, user_row, csv_user_id):
        super(UserVotesThread, self).__init__(name=str(user_row[0]))
        self.user_row = user_row
        self.tor_port = first_tor_port + 2 * csv_user_id
        self.tor_control_port = first_tor_port + 2 * csv_user_id + 1
    def new_tor_ip(self):
        """
        Switch Tor exit IP for this Tor process.
        http://stackoverflow.com/a/18895491/895245
        """
        self.process.send_signal(signal.SIGHUP)
    def start_tor(self):
        torrc_file_path = os.path.join(torrc_dir, str(self.tor_port))
        with open(torrc_file_path, 'w') as torrc_file:
            torrc_file.write('SocksPort {}\nControlPort {}\nDataDirectory {}\n'.format(
                    self.tor_port, self.tor_control_port, os.path.join(torrc_dir, str(self.tor_port) + '.d')))
        self.process = subprocess.Popen(
            ['tor', '-f', torrc_file_path],
            stdout = subprocess.PIPE,
            stderr = subprocess.PIPE,
        )
    def run(self):
        logging.debug('user = ' + str(self.user_row))
        user_id, user_email, user_password = self.user_row
        # TODO if we start running at midnight, we would overestimate the amount of votes used.
        # We could calculate this every time after a vote to increase precision.
        now = datetime.datetime.utcnow()
        today_midnight = datetime.datetime(year=now.year, month=now.month, day=now.day)
        tomorrow_midnight = today_midnight + datetime.timedelta(days=1)
        failures_today = 0
        self.start_tor()
        # Do one connection per thread:
        # http://stackoverflow.com/questions/1680249/how-to-use-sqlite-in-a-multi-threaded-application
        # http://stackoverflow.com/questions/22739590/how-to-share-single-sqlite-connection-in-multi-threaded-python-application
        # If DB locking gets too intense, we could make on DB file per user.
        # http://stackoverflow.com/questions/1365265/on-localhost-how-to-pick-a-free-port-number
        connection = sqlite3.connect(common.schedule_database_path)
        connection.row_factory = sqlite3.Row
        cursor = connection.cursor()
        votes_already_done_today = next(cursor.execute(
                'SELECT COUNT(*) FROM votes ' +
                'WHERE user_id = ? AND vote_time >= ? AND vote_time < ? AND script_status = ?',
                (user_id, today_midnight, tomorrow_midnight, exit_status_success)))[0]
        logging.debug('Votes already done today = ' + str(votes_already_done_today))
        # We could cache this in a variable, and update it as we do operations.
        # The problem is mass update of 404 questions.
        nvotes_not_done = next(cursor.execute(
                'SELECT COUNT(*) FROM votes ' +
                vote_not_done_query,
                (user_id,)))[0]
        while votes_already_done_today < common.max_votes_per_day:
            if nvotes_not_done == 0:
                msg = 'Not enough votes scheduled today for user = {}'.format(user_id)
                logging.warn(msg)
                send_email(msg)
                break
            # Get one random vote and do it. Not very fast,
            # but I could not find a better way, and network is our bottleneck.
            # An faster alternative would be to read 10k rows and pick 30 from them each time.
            # Less random, but also good enough.
            cursor.execute(
                    'SELECT * FROM votes ' +
                    vote_not_done_query +
                    'ORDER BY id ASC  LIMIT 1 OFFSET ?',
                    (user_id, random.randint(1, nvotes_not_done)))
            vote_row = cursor.fetchone()
            if not dry_run_no_server:
                # http://stackoverflow.com/questions/7920284/how-can-printing-an-object-result-in-different-output-than-both-str-and-repr
                logging.debug('vote = ' + str(tuple(vote_row)))
                args = [
                    casperjs_path,
                    '--ssl-protocol=any',
                    '--proxy=127.0.0.1:9050',
                    '--proxy-type=socks5',
                    common.vote_script_path,
                    user_email,
                    user_password,
                    user_id,
                    str(vote_row['question_id']),
                    str(vote_row['answer_id']),
                    script_dir
                ]
                logging.debug('command = ' + ' '.join(args))
                process = subprocess.Popen(
                    args,
                    stdout = subprocess.PIPE,
                    stderr = subprocess.PIPE,
                )
                stdout, stderr = process.communicate()
                logging.debug('stdout = \n' + stdout.rstrip())
                if stderr:
                    logging.error('stderr = \n' + stderr.rstrip())
                exit_status = process.wait()
            else:
                exit_status = 0
            if exit_status == exit_status_cloudfare_attention_required:
                self.new_tor_ip()
            else:
                cursor.execute("""UPDATE votes SET vote_time = ?, script_status = ?
                    WHERE user_id = ? AND answer_id = ?""",
                    (datetime.datetime.utcnow(), exit_status, user_id, vote_row['answer_id']))
                nvotes_not_done -= cursor.rowcount
                connection.commit()
            exit_status_msg = 'Exit status = ' + str(exit_status)
            if exit_status == exit_status_success:
                logging.debug(exit_status_msg)
                votes_already_done_today += 1
            else:
                # The question gave 404, so just skip all answers for that question.
                if exit_status == exit_status_404:
                    cursor.execute("""UPDATE votes SET vote_time = ?, script_status = ?
                        WHERE user_id = ? AND question_id = ?""",
                        (datetime.datetime.utcnow(), exit_status_404, user_id, vote_row['question_id']))
                    nvotes_not_done -= cursor.rowcount
                failures_today += 1
                logging.error(exit_status_msg)
                if failures_today >= max_failures_today:
                    msg = 'Reached maximum failures today for user = {}. Skipping further votes.'.format(user_id)
                    logging.error(msg)
                    send_email(msg)
                    break
        connection.close()

# Is thread safe: http://stackoverflow.com/questions/2973900/is-pythons-logging-module-thread-safe
logging.basicConfig(
    filename = os.path.splitext(os.path.realpath(__file__))[0] + '.log',
    level = logging.DEBUG,
    format = '%(asctime)s | %(levelname)-7s | %(threadName)7s | %(message)s',
)
logging.Formatter.converter = time.gmtime
script_dir = os.path.dirname(os.path.realpath(__file__))
logging.debug(
    'Last git commit SHA = ' +
    subprocess.check_output(['git', '-C', script_dir, 'rev-parse', 'HEAD']))

torrc_dir = os.path.join(script_dir, 'torrc')

if len(sys.argv) > 1:
    casperjs_path = sys.argv[1]
else:
    casperjs_path = '/home/ciro/.nvm/v0.10.26/bin/casperjs'

with open(common.users_csv_path, 'r') as user_file:
    user_csv = csv.reader(user_file)
    threads = []
    for i, user_row in enumerate(common.iterate_users()):
        t = UserVotesThread(user_row, i)
        threads.append(t)
        t.start()
    for t in threads:
        t.join()
